{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "First_GAN_WS_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dwiggles/gans_workshop/blob/master/First_GAN_WS_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJXDSI_H52vD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions.normal import Normal\n",
        "\n",
        "mean = 3.0\n",
        "stddev = 0.2\n",
        "\n",
        "channels = 30\n",
        "\n",
        "g_input_size = 20    \n",
        "g_hidden_size = 150  \n",
        "g_output_size = channels  \n",
        "\n",
        "d_input_size = channels\n",
        "d_hidden_size = 75   \n",
        "d_output_size = 1\n",
        "\n",
        "batch_size = 15\n",
        "\n",
        "num_epochs = 15000\n",
        "print_interval = 1000\n",
        "\n",
        "d_learning_rate = 3e-3\n",
        "g_learning_rate = 8e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mtz51_eb6Tmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_real_sampler(mu, sigma):\n",
        "    dist = Normal(mu, sigma)\n",
        "    return lambda m, n: dist.sample((m, n)).requires_grad_()\n",
        "\n",
        "def get_noise_sampler():\n",
        "    return lambda m, n: torch.rand(m, n).requires_grad_()  # Uniform-dist data into generator, _NOT_ Gaussian\n",
        "\n",
        "actual_data = get_real_sampler(mean, stddev)\n",
        "noise_data = get_noise_sampler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkYqN2m86emy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Generator, self).__init__()\n",
        "        super(Generator, self).__init__()\n",
        "        self.input = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        self.nonLinearity = torch.nn.LeakyReLU()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.nonLinearity(self.input(x))\n",
        "        x = self.nonLinearity( self.hidden(x) )\n",
        "        return self.nonLinearity(self.output(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIk-7hag6izH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Generator Solution {display-mode: \"form\"}\n",
        "\"\"\"\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        self.nonLinearity = torch.nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.nonLinearity(self.input(x))\n",
        "        x = self.nonLinearity( self.hidden(x))\n",
        "        return self.nonLinearity(self.output(x))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIPzq90I7O3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # Fill this in\n",
        "        self.input = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        self.nonLinearity = torch.nn.ELU()\n",
        "        self.nonLinearityOutput = torch.sigmoid\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.nonLinearity(self.input(x))\n",
        "        x = self.nonLinearity(self.hidden(x))\n",
        "        return self.nonLinearityOutput(self.output(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwJudd_f7rpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Discriminator Solution {display-mode: \"form\"}\n",
        "\"\"\"\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        self.nonLinearity = torch.nn.ELU()\n",
        "        self.nonLinearityOutput = torch.sigmoid\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.nonLinearity(self.input(x))\n",
        "        x = self.nonLinearity(self.hidden(x))\n",
        "        return self.nonLinearityOutput(self.output(x))\n",
        "        \n",
        " \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mbc-tOF8NTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
        "D = Discriminator(input_size=d_input_size, hidden_size=d_hidden_size, output_size=d_output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAo1uViR8OEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate)\n",
        "g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7XoCF7E8dA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_D_on_real():\n",
        "    real_data = actual_data(batch_size, d_input_size)\n",
        "    decision = D(real_data)\n",
        "    error = criterion(decision, torch.ones(batch_size, 1))\n",
        "    error.backward() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nZGMacc8f-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_D_on_generated() :\n",
        "  # Fill this in\n",
        "    noise = noise_data(batch_size, g_input_size)\n",
        "    generated_data = G(noise) \n",
        "    decision = D(generated_data)\n",
        "    error = criterion(decision, torch.zeros(batch_size, 1))  # zeros = fake\n",
        "    error.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-pgMgFI8i7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Train D on generated Solution {display-mode: \"form\"}\n",
        "\"\"\"\n",
        "def train_D_on_generated():\n",
        "    noise = noise_data(batch_size, g_input_size)\n",
        "    generated_data = G(noise) \n",
        "    decision = D(generated_data)\n",
        "    error = criterion(decision, torch.zeros(batch_size, 1))  # zeros = fake\n",
        "    error.backward()\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ8bAAiP80op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_G():\n",
        "  # Fill this in\n",
        "  noise = noise_data(batch_size, g_input_size)\n",
        "  generated_data = G(noise)\n",
        "  generated_decision = D(generated_data)\n",
        "  error = criterion(generated_decision, torch.ones(batch_size, 1))  # we want to fool, so pretend it's all genuine\n",
        "\n",
        "  error.backward()\n",
        "  return error.item(), generated_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMl0FnI_85B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Train G Solution {display-mode: \"form\"}\n",
        "\"\"\"\n",
        "def train_G():\n",
        "    noise = noise_data(batch_size, g_input_size)\n",
        "    generated_data = G(noise)\n",
        "    generated_decision = D(generated_data)\n",
        "    error = criterion(generated_decision, torch.ones(batch_size, 1))  # we want to fool, so pretend it's all genuine\n",
        "\n",
        "    error.backward()\n",
        "    return error.item(), generated_data\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJQejpMZ3Gt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training loop\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    D.zero_grad()\n",
        "    \n",
        "    train_D_on_real()    \n",
        "    train_D_on_generated()\n",
        "    d_optimizer.step()\n",
        "    \n",
        "    G.zero_grad()\n",
        "    loss,generated = train_G()\n",
        "    g_optimizer.step()\n",
        "    \n",
        "    losses.append(loss)\n",
        "    \n",
        "    if( epoch % print_interval) == (print_interval - 1):\n",
        "        print(\"Epoch %6d. Loss %5.3f\" % (epoch+1, loss))\n",
        "        \n",
        "print(\"Training complete\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_L5x1IJ9PxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training Loop Solution {display-mode: \"form\"}\n",
        "\n",
        "\"\"\"\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    D.zero_grad()\n",
        "    \n",
        "    train_D_on_real()    \n",
        "    train_D_on_generated()\n",
        "    d_optimizer.step()\n",
        "    \n",
        "    G.zero_grad()\n",
        "    loss,generated = train_G()\n",
        "    g_optimizer.step()\n",
        "    \n",
        "    losses.append(loss)\n",
        "    if( epoch % print_interval) == (print_interval - 1):\n",
        "        print(\"Epoch %6d. Loss %5.3f\" % (epoch+1, loss))\n",
        "        \n",
        "print(\"Training complete\")\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3ah9c0c9da7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw(data): \n",
        "    plt.clf()\n",
        "    plt.figure()\n",
        "    d = data.tolist() if isinstance(data, torch.Tensor ) else data\n",
        "    plt.plot(d) \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqW0tkIQ9j4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generated distributions\n",
        "\n",
        "\n",
        "generated_distributions = torch.empty(generated.size(0), 15) \n",
        "for i in range(0, generated_distributions.size(0)) :\n",
        "    generated_distributions[i] = torch.histc(generated[i], min=0, max=15, bins=15)\n",
        "draw(generated_distributions.t())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-b-Exwh9m1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Real distributions\n",
        "\n",
        "real_distributions = torch.empty(generated.size(0), 15) \n",
        "real_data = actual_data(batch_size, d_input_size)\n",
        "\n",
        "for i in range(generated.size(0)):\n",
        "  real_distributions[i] = torch.histc(real_data[i], min=0, max=15, bins=15)\n",
        "draw(real_distributions.t())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}